---
title: General In-hand Object Rotation with Vision and Touch
section: Poster
openreview: RN00jfIV-X
abstract: We introduce Rotateit, a system that enables fingertip-based object rotation
  along multiple axes by leveraging multimodal sensory inputs. Our system is trained
  in simulation, where it has access to ground-truth object shapes and physical properties.
  Then we distill it to operate on realistic yet noisy simulated visuotactile and
  proprioceptive sensory inputs. These multimodal inputs are fused via a visuotactile
  transformer, enabling online inference of object shapes and physical properties
  during deployment. We show significant performance improvements over prior methods
  and highlight the importance of visual and tactile sensing.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: qi23a
month: 0
tex_title: General In-hand Object Rotation with Vision and Touch
firstpage: 2549
lastpage: 2564
page: 2549-2564
order: 2549
cycles: false
bibtex_author: Qi, Haozhi and Yi, Brent and Suresh, Sudharshan and Lambeta, Mike and
  Ma, Yi and Calandra, Roberto and Malik, Jitendra
author:
- given: Haozhi
  family: Qi
- given: Brent
  family: Yi
- given: Sudharshan
  family: Suresh
- given: Mike
  family: Lambeta
- given: Yi
  family: Ma
- given: Roberto
  family: Calandra
- given: Jitendra
  family: Malik
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/qi23a/qi23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
