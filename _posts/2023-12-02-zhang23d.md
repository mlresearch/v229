---
title: Robust Reinforcement Learning in Continuous Control Tasks with Uncertainty
  Set Regularization
section: Poster
openreview: keAPCON4jHC
abstract: Reinforcement learning (RL) is recognized as lacking generalization and
  robustness under environmental perturbations, which excessively restricts its application
  for real-world robotics. Prior work claimed that adding regularization to the value
  function is equivalent to learning a robust policy under uncertain transitions.
  Although the regularization-robustness transformation is appealing for its simplicity
  and efficiency, it is still lacking in continuous control tasks. In this paper,
  we propose a new regularizer named Uncertainty Set Regularizer (USR), to formulate
  the uncertainty set on the parametric space of a transition function. To deal with
  unknown uncertainty sets, we further propose a novel adversarial approach to generate
  them based on the value function. We evaluate USR on the Real-world Reinforcement
  Learning (RWRL) benchmark and the Unitree A1 Robot, demonstrating improvements in
  the robust performance of perturbed testing environments and sim-to-real scenarios.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang23d
month: 0
tex_title: Robust Reinforcement Learning in Continuous Control Tasks with Uncertainty
  Set Regularization
firstpage: 1400
lastpage: 1424
page: 1400-1424
order: 1400
cycles: false
bibtex_author: Zhang, Yuan and Wang, Jianhong and Boedecker, Joschka
author:
- given: Yuan
  family: Zhang
- given: Jianhong
  family: Wang
- given: Joschka
  family: Boedecker
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/zhang23d/zhang23d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
