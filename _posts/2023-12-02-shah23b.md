---
title: 'MUTEX: Learning Unified Policies from Multimodal Task Specifications'
section: Poster
openreview: PwqiqaaEzJ
abstract: Humans use different modalities, such as speech, text, images, videos, etc.,
  to communicate their intent and goals with teammates. For robots to become better
  assistants, we aim to endow them with the ability to follow instructions and understand
  tasks specified by their human partners. Most robotic policy learning methods have
  focused on one single modality of task specification while ignoring the rich cross-modal
  information. We present MUTEX, a unified approach to policy learning from multimodal
  task specifications. It trains a transformer-based architecture to facilitate cross-modal
  reasoning, combining masked modeling and cross-modal matching objectives in a two-stage
  training procedure. After training, MUTEX can follow a task specification in any
  of the six learned modalities (video demonstrations, goal images, text goal descriptions,
  text instructions, speech goal descriptions, and speech instructions) or a combination
  of them. We systematically evaluate the benefits of MUTEX in a newly designed dataset
  with 100 tasks in simulation and 50 tasks in the real world, annotated with multiple
  instances of task specifications in different modalities, and observe improved performance
  over methods trained specifically for any single modality. More information at https://ut-austin-rpl.github.io/MUTEX/
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shah23b
month: 0
tex_title: 'MUTEX: Learning Unified Policies from Multimodal Task Specifications'
firstpage: 2663
lastpage: 2682
page: 2663-2682
order: 2663
cycles: false
bibtex_author: Shah, Rutav and Mart\'{i}n-Mart\'{i}n, Roberto and Zhu, Yuke
author:
- given: Rutav
  family: Shah
- given: Roberto
  family: Martín-Martín
- given: Yuke
  family: Zhu
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/shah23b/shah23b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
