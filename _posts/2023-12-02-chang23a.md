---
title: A Data-Efficient Visual-Audio Representation with Intuitive Fine-tuning for
  Voice-Controlled Robots
section: Poster
openreview: dxOaNO8bge
abstract: A command-following robot that serves people in everyday life must continually
  improve itself in deployment domains with minimal help from its end users, instead
  of engineers. Previous methods are either difficult to continuously improve after
  the deployment or require a large number of new labels during fine-tuning. Motivated
  by (self-)supervised contrastive learning, we propose a novel representation that
  generates an intrinsic reward function for command-following robot tasks by associating
  images with sound commands. After the robot is deployed in a new domain, the representation
  can be updated intuitively and data-efficiently by non-experts without any hand-crafted
  reward functions. We demonstrate our approach on various sound types and robotic
  tasks, including navigation and manipulation with raw sensor inputs. In simulated
  and real-world experiments, we show that our system can continually self-improve
  in previously unseen scenarios given fewer new labeled data, while still achieving
  better performance over previous methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chang23a
month: 0
tex_title: A Data-Efficient Visual-Audio Representation with Intuitive Fine-tuning
  for Voice-Controlled Robots
firstpage: 1797
lastpage: 1819
page: 1797-1819
order: 1797
cycles: false
bibtex_author: Chang, Peixin and Liu, Shuijing and Ji, Tianchen and Chakraborty, Neeloy
  and Hong, Kaiwen and Driggs-Campbell, Katherine Rose
author:
- given: Peixin
  family: Chang
- given: Shuijing
  family: Liu
- given: Tianchen
  family: Ji
- given: Neeloy
  family: Chakraborty
- given: Kaiwen
  family: Hong
- given: Katherine Rose
  family: Driggs-Campbell
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/chang23a/chang23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
