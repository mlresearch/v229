---
title: Action-Quantized Offline Reinforcement Learning for Robotic Skill Learning
section: Poster
openreview: n9lew97SAn
abstract: The offline reinforcement learning (RL) paradigm provides a general recipe
  to convert static behavior datasets into policies that can perform better than the
  policy that collected the data. While policy constraints, conservatism, and other
  methods for mitigating distributional shifts have made offline reinforcement learning
  more effective, the continuous action setting often necessitates various approximations
  for applying these techniques. Many of these challenges are greatly alleviated in
  discrete action settings, where offline RL constraints and regularizers can often
  be computed more precisely or even exactly. In this paper, we propose an adaptive
  scheme for action quantization. We use a VQ-VAE to learn state- conditioned action
  quantization, avoiding the exponential blowup that comes with na√Øve discretization
  of the action space. We show that several state-of-the-art offline RL methods such
  as IQL, CQL, and BRAC improve in performance on benchmarks when combined with our
  proposed discretization scheme. We further validate our approach on a set of challenging
  long-horizon complex robotic manipulation tasks in the Robomimic environment, where
  our discretized offline RL algorithms are able to improve upon their continuous
  counterparts by 2-3x. Our project page is at saqrl.github.io
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: luo23a
month: 0
tex_title: Action-Quantized Offline Reinforcement Learning for Robotic Skill Learning
firstpage: 1348
lastpage: 1361
page: 1348-1361
order: 1348
cycles: false
bibtex_author: Luo, Jianlan and Dong, Perry and Wu, Jeffrey and Kumar, Aviral and
  Geng, Xinyang and Levine, Sergey
author:
- given: Jianlan
  family: Luo
- given: Perry
  family: Dong
- given: Jeffrey
  family: Wu
- given: Aviral
  family: Kumar
- given: Xinyang
  family: Geng
- given: Sergey
  family: Levine
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/luo23a/luo23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
