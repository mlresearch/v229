---
title: An Unbiased Look at Datasets for Visuo-Motor Pre-Training
section: Poster
openreview: qVc7NWYTRZ6
abstract: Visual representation learning hold great promise for robotics, but is severely
  hampered by the scarcity and homogeneity of robotics datasets. Recent works address
  this problem by pre-training visual representations on large-scale but out-of-domain
  data (e.g., videos of egocentric interactions) and then transferring them to target
  robotics tasks. While the field is heavily focused on developing better pre-training
  algorithms, we find that dataset choice is just as important to this paradigm’s
  success. After all, the representation can only learn the structures or priors present
  in the pre-training dataset. To this end, we flip the focus on algorithms, and instead
  conduct a dataset centric analysis of robotic pre-training. Our findings call into
  question some common wisdom in the field. We observe that traditional vision datasets
  (like ImageNet, Kinetics and 100 Days of Hands) are surprisingly competitive options
  for visuo-motor representation learning, and that the pre-training dataset’s image
  distribution matters more than its size. Finally, we show that common simulation
  benchmarks are not a reliable proxy for real world performance and that simple regularization
  strategies can dramatically improve real world policy learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dasari23a
month: 0
tex_title: An Unbiased Look at Datasets for Visuo-Motor Pre-Training
firstpage: 1183
lastpage: 1198
page: 1183-1198
order: 1183
cycles: false
bibtex_author: Dasari, Sudeep and Srirama, Mohan Kumar and Jain, Unnat and Gupta,
  Abhinav
author:
- given: Sudeep
  family: Dasari
- given: Mohan Kumar
  family: Srirama
- given: Unnat
  family: Jain
- given: Abhinav
  family: Gupta
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/dasari23a/dasari23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
