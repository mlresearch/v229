---
title: Open-World Object Manipulation using Pre-Trained Vision-Language Models
section: Poster
openreview: 9al6taqfTzr
abstract: 'For robots to follow instructions from people, they must be able to connect
  the rich semantic information in human vocabulary, e.g. “can you get me the pink
  stuffed whale?” to their sensory observations and actions. This brings up a notably
  difficult challenge for robots: while robot learning approaches allow robots to
  learn many different behaviors from first-hand experience, it is impractical for
  robots to have first-hand experiences that span all of this semantic information.
  We would like a robot’s policy to be able to perceive and pick up the pink stuffed
  whale, even if it has never seen any data interacting with a stuffed whale before.
  Fortunately, static data on the internet has vast semantic information, and this
  information is captured in pre-trained vision-language models. In this paper, we
  study whether we can interface robot policies with these pre-trained models, with
  the aim of allowing robots to complete instructions involving object categories
  that the robot has never seen first-hand. We develop a simple approach, which we
  call Manipulation of Open-World Objects (MOO), which leverages a pre-trained vision-language
  model to extract object-identifying information from the language command and image,
  and conditions the robot policy on the current image, the instruction, and the extracted
  object information. In a variety of experiments on a real mobile manipulator, we
  find that MOO generalizes zero-shot to a wide range of novel object categories and
  environments. In addition, we show how MOO generalizes to other, non-language-based
  input modalities to specify the object of interest such as finger pointing, and
  how it can be further extended to enable open-world navigation and manipulation.
  The project’s website and evaluation videos can be found at https://robot-moo.github.io/.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: stone23a
month: 0
tex_title: Open-World Object Manipulation using Pre-Trained Vision-Language Models
firstpage: 3397
lastpage: 3417
page: 3397-3417
order: 3397
cycles: false
bibtex_author: Stone, Austin and Xiao, Ted and Lu, Yao and Gopalakrishnan, Keerthana
  and Lee, Kuang-Huei and Vuong, Quan and Wohlhart, Paul and Kirmani, Sean and Zitkovich,
  Brianna and Xia, Fei and Finn, Chelsea and Hausman, Karol
author:
- given: Austin
  family: Stone
- given: Ted
  family: Xiao
- given: Yao
  family: Lu
- given: Keerthana
  family: Gopalakrishnan
- given: Kuang-Huei
  family: Lee
- given: Quan
  family: Vuong
- given: Paul
  family: Wohlhart
- given: Sean
  family: Kirmani
- given: Brianna
  family: Zitkovich
- given: Fei
  family: Xia
- given: Chelsea
  family: Finn
- given: Karol
  family: Hausman
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/stone23a/stone23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
