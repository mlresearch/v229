---
title: 'Cold Diffusion on the Replay Buffer: Learning to Plan from Known Good States'
section: Poster
openreview: AyRr_i028w
abstract: Learning from demonstrations (LfD) has successfully trained robots to exhibit
  remarkable generalization capabilities. However, many powerful imitation techniques
  do not prioritize the feasibility of the robot behaviors they generate. In this
  work, we explore the feasibility of plans produced by LfD. As in prior work, we
  employ a temporal diffusion model with fixed start and goal states to facilitate
  imitation through in-painting. Unlike previous studies, we apply cold diffusion
  to ensure the optimization process is directed through the agent’s replay buffer
  of previously visited states. This routing approach increases the likelihood that
  the final trajectories will predominantly occupy the feasible region of the robot’s
  state space. We test this method in simulated robotic environments with obstacles
  and observe a significant improvement in the agent’s ability to avoid these obstacles
  during planning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang23e
month: 0
tex_title: 'Cold Diffusion on the Replay Buffer: Learning to Plan from Known Good
  States'
firstpage: 3277
lastpage: 3291
page: 3277-3291
order: 3277
cycles: false
bibtex_author: Wang, Zidan and Oba, Takeru and Yoneda, Takuma and Shen, Rui and Walter,
  Matthew and Stadie, Bradly C.
author:
- given: Zidan
  family: Wang
- given: Takeru
  family: Oba
- given: Takuma
  family: Yoneda
- given: Rui
  family: Shen
- given: Matthew
  family: Walter
- given: Bradly C.
  family: Stadie
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/wang23e/wang23e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
