---
title: Online Model Adaptation with Feedforward Compensation
section: Poster
openreview: 4x2RUQ99sGz
abstract: To cope with distribution shifts or non-stationarity in system dynamics,
  online adaptation algorithms have been introduced to update offline-learned prediction
  models in real-time. Existing online adaptation methods focus on optimizing the
  prediction model by utilizing feedback from the latest prediction error. Unfortunately,
  this feedback-based approach is susceptible to forgetting past information. This
  work proposes an online adaptation method with feedforward compensation, which uses
  critical data samples from a memory buffer, instead of the latest samples, to optimize
  the prediction model. We prove that the proposed approach achieves a smaller error
  bound compared to previously utilized methods in slow time-varying systems. We conducted
  experiments on several prediction tasks, which clearly illustrate the superiority
  of the proposed feedforward adaptation method. Furthermore, our feedforward adaptation
  technique is capable of estimating an uncertainty bound for predictions.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: abuduweili23a
month: 0
tex_title: Online Model Adaptation with Feedforward Compensation
firstpage: 3687
lastpage: 3709
page: 3687-3709
order: 3687
cycles: false
bibtex_author: Abuduweili, Abulikemu and Liu, Changliu
author:
- given: Abulikemu
  family: Abuduweili
- given: Changliu
  family: Liu
date: 2023-12-02
address:
container-title: Proceedings of The 7th Conference on Robot Learning
volume: '229'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 12
  - 2
pdf: https://proceedings.mlr.press/v229/abuduweili23a/abuduweili23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
